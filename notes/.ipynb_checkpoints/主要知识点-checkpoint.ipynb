{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造CIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textrank\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "import networkx as nx\n",
    "\n",
    "def textrank(sentences):\n",
    "    \"\"\"\n",
    "    Given input text, split sentences and calc text rank score.\n",
    "    :param sentences: input sentence list\n",
    "    :return: a dictionary of (sentence index, sentence score)\n",
    "    \"\"\"\n",
    "    bow_matrix = CountVectorizer().fit_transform(sentences)\n",
    "    normalized = TfidfTransformer().fit_transform(bow_matrix)\n",
    "    similarity_graph = normalized * normalized.T\n",
    "    nx_graph = nx.from_scipy_sparse_matrix(similarity_graph)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    return dict(((i, scores[i]) for i, s in enumerate(sentences)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding local matching vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算tf\n",
    "\n",
    "def gen_tf(text):\n",
    "    \"\"\"\n",
    "    Given a segmented string, return a dict of tf.\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    total = len(tokens)\n",
    "    tf_dict = {}\n",
    "    for w in tokens:\n",
    "        tf_dict[w] = tf_dict.get(w, 0.0) + 1.0\n",
    "    for k in tf_dict:\n",
    "        tf_dict[k] /= total\n",
    "    return tf_dict\n",
    "\n",
    "def tf_cos_sim(text1, text2):\n",
    "    tf1 = gen_tf(text1)\n",
    "    tf2 = gen_tf(text2)\n",
    "    return cosine_sim(tf1, tf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算tf-idf\n",
    "def gen_tfidf(text, idf_dict):\n",
    "    \"\"\"\n",
    "    Given a segmented string and idf dict, return a dict of tfidf.\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    total = len(tokens)\n",
    "    tfidf_dict = {}\n",
    "    for w in tokens:\n",
    "        tfidf_dict[w] = tfidf_dict.get(w, 0.0) + 1.0\n",
    "    for k in tfidf_dict:\n",
    "        tfidf_dict[k] *= idf_dict.get(k, 0.0) / total\n",
    "    return tfidf_dict\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    if len(b) < len(a):\n",
    "        a, b = b, a\n",
    "    res = 0\n",
    "    for key, a_value in a.items():\n",
    "        res += a_value * b.get(key, 0)\n",
    "    if res == 0:\n",
    "        return 0\n",
    "    try:\n",
    "        res = res / (norm(list(a.values())) * norm(list(b.values())))\n",
    "    except ZeroDivisionError:\n",
    "        res = 0\n",
    "    return res\n",
    "\n",
    "def tfidf_cos_sim(text1, text2, idf_dict):\n",
    "    tfidf1 = gen_tfidf(text1, idf_dict)\n",
    "    tfidf2 = gen_tfidf(text2, idf_dict)\n",
    "    return cosine_sim(tfidf1, tfidf2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaccard\n",
    "def jaccard_common_words(text1, text2):\n",
    "    str1 = set(str(text1).split())\n",
    "    str2 = set(str(text2).split())\n",
    "    if len(str1) == 0 or len(str2) == 0:\n",
    "        return 0.0\n",
    "    return float(len(str1 & str2)) / len(str1 | str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ochiai\n",
    "def ochiai_common_words(text1, text2):\n",
    "    str1 = set(str(text1).split())\n",
    "    str2 = set(str(text2).split())\n",
    "    if len(str1) == 0 or len(str2) == 0:\n",
    "        return 0.0\n",
    "    return float(len(str1 & str2)) / math.sqrt(len(str1) * len(str2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_bm25\n",
    "from gensim.summarization import bm25\n",
    "def build_bm25(corpus):\n",
    "    corpus = []\n",
    "    bm25Model = bm25.BM25(corpus)\n",
    "\n",
    "    return bm25Model\n",
    "\n",
    "\n",
    "def cal_bm25_sim(bm25Model, tokens1, tokens2):\n",
    "    ts1, ts2 = tokens1, tokens2\n",
    "    if len(tokens1) > len(tokens2):\n",
    "        ts1 = tokens2\n",
    "        ts2 = tokens1\n",
    "    freqs = {}\n",
    "    for word in ts2:\n",
    "        if word not in freqs:\n",
    "            freqs[word] = 0\n",
    "        freqs[word] += 1\n",
    "\n",
    "    param_k1 = 1.5\n",
    "    param_b = 0.75\n",
    "    score1, score2 = 0.0, 0.0\n",
    "    for word in ts1:\n",
    "        if word not in freqs or word not in bm25Model.idf:\n",
    "            continue\n",
    "        score1 += (bm25Model.idf[word] * freqs[word] * (param_k1 + 1) / (\n",
    "            freqs[word] + param_k1 * (1 - param_b + param_b * 1)))\n",
    "    for word in ts2:\n",
    "        if word not in freqs or word not in bm25Model.idf:\n",
    "            continue\n",
    "        score2 += (bm25Model.idf[word] * freqs[word] * (param_k1 + 1) / (\n",
    "            freqs[word] + param_k1 * (1 - param_b + param_b * 1)))\n",
    "\n",
    "    sim = score1 / score2 if score2 > 0 else 0\n",
    "    sim = sim if sim <= 1.0 else 1.0\n",
    "    return sim\n",
    "\n",
    "tokens1 = '我们 的 目标 就 是 能够 使用 海量 用户 搜索 日志'\n",
    "tokens2 = '在 海量 数据 里 挖掘 潜藏 的 查询 之间 的 结构 信息'\n",
    "sim = cal_bm25_sim(bm25Model, tokens1, tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
