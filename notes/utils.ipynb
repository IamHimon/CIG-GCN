{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1 = '我们 的 目标 就 是 能够 使用 海量 用户 搜索 日志'\n",
    "tokens2 = '在 海量 数据 里 挖掘 潜藏 的 查询 之间 的 结构 信息'\n",
    "token3 = 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textrank\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "import networkx as nx\n",
    "\n",
    "def textrank(sentences):\n",
    "    \"\"\"\n",
    "    Given input text, split sentences and calc text rank score.\n",
    "    :param sentences: input sentence list\n",
    "    :return: a dictionary of (sentence index, sentence score)\n",
    "    \"\"\"\n",
    "    bow_matrix = CountVectorizer().fit_transform(sentences)\n",
    "    normalized = TfidfTransformer().fit_transform(bow_matrix)\n",
    "    similarity_graph = normalized * normalized.T\n",
    "    nx_graph = nx.from_scipy_sparse_matrix(similarity_graph)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    return dict(((i, scores[i]) for i, s in enumerate(sentences)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.4651161545800183, 1: 0.4651161545800183, 2: 0.06976769083996354}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textrank([tokens1,tokens2,token3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding local matching vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import norm\n",
    "def cosine_sim(a, b):\n",
    "    if len(b) < len(a):\n",
    "        a, b = b, a\n",
    "    res = 0\n",
    "    for key, a_value in a.items():\n",
    "        res += a_value * b.get(key, 0)\n",
    "    if res == 0:\n",
    "        return 0\n",
    "    try:\n",
    "        res = res / (norm(list(a.values())) * norm(list(b.values())))\n",
    "    except ZeroDivisionError:\n",
    "        res = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "idf_dict = {}\n",
    "token = tokens1 + tokens2\n",
    "\n",
    "for t in token.split():\n",
    "    idf_dict[t] = random.uniform(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'我们': 0.8475428640922156,\n",
       " '的': 1.7121881952212235,\n",
       " '目标': 1.4821940926689208,\n",
       " '就': 0.8199354451619345,\n",
       " '是': 1.8112978956401107,\n",
       " '能够': 1.2703013045679612,\n",
       " '使用': 1.7615470961490607,\n",
       " '海量': 1.1333676073051475,\n",
       " '用户': 1.8409108187581233,\n",
       " '搜索': 0.5745408255349125,\n",
       " '日志在': 0.6124637272657749,\n",
       " '数据': 1.2308230393632884,\n",
       " '里': 0.007054410825109825,\n",
       " '挖掘': 1.4386600190268888,\n",
       " '潜藏': 0.40411136261439706,\n",
       " '查询': 0.3333993802165316,\n",
       " '之间': 0.8665756696285858,\n",
       " '结构': 1.036542920893356,\n",
       " '信息': 1.5550139196068333}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 计算tf\n",
    "\n",
    "<div>\n",
    "<img src='imgs/tf.png' width='300' height='300'/>\n",
    "</div>\n",
    "\n",
    "## 2. 计算tf-idf\n",
    "\n",
    "<div>\n",
    "<img src='imgs/tfidf.png' width='500' height='500'/>\n",
    "</div>\n",
    "\n",
    "## 3. jaccard\n",
    "\n",
    "<div>\n",
    "<img src='imgs/jaccard.png' width='300' height='300'/>\n",
    "</div>\n",
    "\n",
    "## 4. ochiai\n",
    "\n",
    "<div>\n",
    "<img src='imgs/ochiai.png' width='300' height='300'/>\n",
    "</div>\n",
    "\n",
    "## 5. BM25\n",
    "\n",
    "<div>\n",
    "<img src='imgs/bm25.png' width='600' height='600'/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2417468892076141"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算tf\n",
    "\n",
    "def gen_tf(text):\n",
    "    \"\"\"\n",
    "    Given a segmented string, return a dict of tf.\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    total = len(tokens)\n",
    "    tf_dict = {}\n",
    "    for w in tokens:\n",
    "        tf_dict[w] = tf_dict.get(w, 0.0) + 1.0\n",
    "    for k in tf_dict:\n",
    "        tf_dict[k] /= total\n",
    "    return tf_dict\n",
    "\n",
    "def tf_cos_sim(text1, text2):\n",
    "    tf1 = gen_tf(text1)\n",
    "    tf2 = gen_tf(text2)\n",
    "    return cosine_sim(tf1, tf2)\n",
    "\n",
    "\n",
    "tf_cos_sim(tokens1, tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.352082200987131"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 给定idf， 求计算tf-idf\n",
    "def gen_tfidf(text, idf_dict):\n",
    "    \"\"\"\n",
    "    Given a segmented string and idf dict, return a dict of tfidf.\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    total = len(tokens)\n",
    "    tfidf_dict = {}\n",
    "    for w in tokens:  # 求词频\n",
    "        tfidf_dict[w] = tfidf_dict.get(w, 0.0) + 1.0\n",
    "    for k in tfidf_dict:  # 除以总个数\n",
    "        tfidf_dict[k] *= idf_dict.get(k, 0.0) / total\n",
    "    return tfidf_dict\n",
    "\n",
    "\n",
    "def tfidf_cos_sim(text1, text2, idf_dict):\n",
    "    tfidf1 = gen_tfidf(text1, idf_dict)\n",
    "    tfidf2 = gen_tfidf(text2, idf_dict)\n",
    "    return cosine_sim(tfidf1, tfidf2)\n",
    "\n",
    "tfidf_cos_sim(tokens1, tokens2, idf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jaccard\n",
    "def jaccard_common_words(text1, text2):\n",
    "    str1 = set(str(text1).split())\n",
    "    str2 = set(str(text2).split())\n",
    "    if len(str1) == 0 or len(str2) == 0:\n",
    "        return 0.0\n",
    "    return float(len(str1 & str2)) / len(str1 | str2)\n",
    "\n",
    "jaccard_common_words(tokens1, tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18181818181818182"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ochiai\n",
    "# \n",
    "import math\n",
    "def ochiai_common_words(text1, text2):\n",
    "    str1 = set(str(text1).split())\n",
    "    str2 = set(str(text2).split())\n",
    "    if len(str1) == 0 or len(str2) == 0:\n",
    "        return 0.0\n",
    "    return float(len(str1 & str2)) / math.sqrt(len(str1) * len(str2))\n",
    "\n",
    "ochiai_common_words(tokens1, tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6189436747502947"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bm25\n",
    "# 单词与query的部分通常省略掉\n",
    "# 参考：https://www.programmersought.com/article/51573171512/\n",
    "\n",
    "def cal_bm25_sim(tokens1, tokens2, idf_dict):\n",
    "    ts1, ts2 = tokens1, tokens2\n",
    "    if len(tokens1) > len(tokens2):\n",
    "        ts1 = tokens2   # 短的作为query\n",
    "        ts2 = tokens1\n",
    "    \n",
    "    freqs = {}  # 文档中的词频 tf_td\n",
    "    for word in ts2:\n",
    "        if word not in freqs:\n",
    "            freqs[word] = 0\n",
    "        freqs[word] += 1\n",
    "\n",
    "    param_k1 = 1.5\n",
    "    param_b = 0.75\n",
    "    \n",
    "    score1, score2 = 0.0, 0.0\n",
    "    \n",
    "    \n",
    "    for word in ts1:\n",
    "        if word not in freqs or word not in idf_dict:\n",
    "            continue\n",
    "        score1 += idf_dict[word] * (freqs[word] * (param_k1 + 1) / (\n",
    "            freqs[word] + param_k1 * (1 - param_b + param_b * 1)))\n",
    "        \n",
    "    for word in ts2:\n",
    "        if word not in freqs or word not in idf_dict:\n",
    "            continue\n",
    "        score2 += idf_dict[word] * (freqs[word] * (param_k1 + 1) / (\n",
    "            freqs[word] + param_k1 * (1 - param_b + param_b * 1)))\n",
    "        \n",
    "\n",
    "    sim = score1 / score2 if score2 > 0 else 0\n",
    "    sim = sim if sim <= 1.0 else 1.0\n",
    "    return sim\n",
    "\n",
    "\n",
    "cal_bm25_sim('海量 用户'.split(), '用户'.split(), idf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
